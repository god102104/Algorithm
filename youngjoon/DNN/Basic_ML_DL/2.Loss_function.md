# Loss function

손실 함수 

손실 함수는 분류에 따라 다른 함수를 사용한다. 

1. Classification
   - Binary Classification
   - Multi-class Classification
   - Multi-label Classification
2. Regression


---

# ✅ 회귀(Regression) 문제

## 🔹 기본적인 손실 함수

**Mean Squared Error (MSE)**  
수식:  
$$
L = \frac{1}{n} \sum (y - \hat{y})^2
$$  
✔️ 가장 기본적, 큰 오차에 민감

**Mean Absolute Error (MAE)**  
수식:  
$$
L = \frac{1}{n} \sum |y - \hat{y}|
$$  
✔️ 이상치에 덜 민감

**Huber Loss**  
✔️ MSE와 MAE의 절충안  
📌 PyTorch: `nn.SmoothL1Loss`

---

# ✅ 딥러닝 특수 목적

| 목적 | 손실 함수 | 설명 |
|------|------------|------|
| GAN | Binary Cross Entropy / Wasserstein Loss | Generator vs Discriminator 학습 |
| Object Detection | Focal Loss, IoU Loss | 클래스 불균형 대처 (e.g. RetinaNet) |
| Image Segmentation | Dice Loss, IoU Loss, Cross Entropy | 픽셀 단위 분류 |
| Ranking | Triplet Loss, Contrastive Loss | 임베딩 거리 기반 학습 (e.g. 얼굴 인식) |
| Self-Supervised | InfoNCE Loss | 표현 학습용 |

